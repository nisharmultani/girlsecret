# robots.txt for GirlSecret
# This file tells search engines which pages they can crawl

# Allow all search engines to crawl everything
User-agent: *
Allow: /

# Disallow crawling of admin and private pages
Disallow: /api/
Disallow: /checkout
Disallow: /cart

# Allow specific bots full access
User-agent: Googlebot
Allow: /

User-agent: Googlebot-Image
Allow: /

User-agent: Bingbot
Allow: /

# Sitemap location
Sitemap: https://girlsecret.com/sitemap.xml
